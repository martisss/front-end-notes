# 计网

## 概述

### ISP(网络服务提供商)

### 主机间通讯方式

c/s
p2p

### 电路交换与分组交换

前者用于电话通信系统，线路利用率低
后者每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响

### 时延

总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延

### 计算机网络体系结构

几种常用的[广域网](https://baike.baidu.com/item/广域网)：[公用电话交换网](https://baike.baidu.com/item/公用电话交换网)（ P S T N）、分组交换网（X . 2 5）、[数字数据网](https://baike.baidu.com/item/数字数据网)（ D D N）、[帧中继](https://baike.baidu.com/item/帧中继)（ F R）、[交换式多兆位数据服务](https://baike.baidu.com/item/交换式多兆位数据服务)（ S M D S）和[异步传输模式](https://baike.baidu.com/item/异步传输模式)（AT M）。

> **局域网技术**
>
> 令牌环网
>
> 光纤分布式数据接口FDDI（Fiber Distributed Data Interface）
>
> **广域网技术**
>
> 综合业务数字网（ISDN）就是一种采用电路交换技术的广域网技术。
>
> ATM，帧中继，SMDS以及X.25等都是采用包交换技术的广域网技术。

- 五层协议
- OSI
- TCP/IP

![image.png](https://s2.loli.net/2022/02/09/eIgm7dLpuWsOj1H.png)



  **物理层：**通过媒介传输比特,确定机械及电气规范（比特Bit）

  **数据链路层**：将比特组装成帧和点到点的传递（帧Frame）

  **网络层**：负责数据包从源到宿的传递和网际互连（包PackeT）

  **传输层**：提供端到端的可靠报文传递和错误恢复（段Segment）

  **会话层**：建立、管理和终止会话（会话协议数据单元SPDU）

  **表示层**：对数据进行翻译、加密和压缩（表示协议数据单元PPDU）

  **应用层**：允许访问OSI环境的手段（应用协议数据单元APDU）

> **网桥（Bridge)**也称为桥接器，是连接两个局域网的存储转发设备，用它可以使完全具有相同或相似体系结构网络系统的连接，这样不但能扩展网络的距离或范围，而且可提高网络的性能、可靠性和安全性。网桥工作在OSI参考模型的数据链路层（第二层），将两个LAN连起来，根据MAC地址来转发帧。
>
> > 网桥的基本特征：
> >
> > 1. 网桥在数据链路层上实现局域网互连
> > 2. **网桥能够互连两个采用不同数据链路层协议、不同传输介质与不同传输速率的网络**
> > 3. 网桥以接收、存储、地址过滤与转发的方式实现互连的网络之间的通信
> > 4. 网桥需要互连的网络在数据链路层以上采用相同的协议**（**OSI七层模型从下到上：物理层 数据链路层 **网络层 传输层 会话层 表示层 应用层**）
> > 5. 网桥可以分隔两个网络之间的通信量，有利于改善互连网络的性能与安全性
>
> **交换机**是主导网络系统的集线设备，大部分交换机是在OSI参考模型的数据链路层（第二层）操作。
>
> 值得注意的是，**网桥与交换机的区别在于市场，而不在与技术**。交换机对网络进行分段的方式与网桥相同，**交换机就是一个多端口的网桥**。确切地说，**高端口密度的网桥就称为局域网交换机**
>
> **网关**工作在传输层及以上层次
>
> > **交换机攻击主要有以下5种类型：**
> >
> > **1.**VLAN跳跃攻击
> >
> > **2.**生成树攻击
> >
> > **3.**MAC表洪水攻击
> >
> > **4.**ARP攻击
> >
> > **5.**VTP攻击
> >
> > DCHP攻击：利用了交换机端口安全功能，MAC动态地址锁和端口静态绑定MAC，来限定交换机某个端口上可以访问网络的MAC地址，从而进行控制。
> >
> > 而目录遍历攻击是HTTP所存在的一个安全漏洞，它使得攻击者能够访问受限的目录，并在Web服务器的根目录以外执行命令。不属于交换机攻击

### 数据在各层之间传递

在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。

决定局域网特性的主要技术要素包括**网络拓扑结构、传输介质与介质访问控制方法**。其中最主要的是**介质访问控制方法。**

![image.png](https://s2.loli.net/2022/02/09/BZcOWPozXigf1kw.png)

## 物理层

物理层的特性有机械特性、电气特性、规程特性和功能特性

### 通信方式

单工，半双工，全双工

在计算机网络中，带宽表示网络的通信线路所能传送数据的能力，是数字信道所能传送的“最高数据率”的同意语，单位是“比特每秒”(b/s)

  吞吐量：表示在单位时间内通过某个网络(或信道、接口)的数据量。吞吐量受网络的带宽或网络的额定速率的限制。

### 带通调制

把离散的数字信号转换为连续的模拟信号

### mac地址

MAC地址又称硬件地址或物理地址，它是由网卡决定的，也就是固定且唯一的，前24位是由IEEE机构分配给厂家，而后24位可以由厂家自己分配。

> 最小帧长=总线传播时延* 数据传输速率* 2	

## 链路层

### 基本问题

- 封装成帧

  将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。

- 透明传输

  简单的说就是什么都可以传，帧使用首部（SOH）和尾部(EOT)定界， 如果数据部分含有首部尾部内容，则需要使用转义字符(ESC)

- 差错检测

  广泛使用了循环冗余检验（CRC）来检查比特差错

### **主要功能**

（前五个为重点）：用于两个设备(同一种数据链路节点)之间进行信息传递。

**1.成帧(帧同步)：避免接收到的位数量以及数值发生异常。**

**2. 差错控制：为了确保数据通信的准确，降低错误发生的几率。**

**3. 流量控制：了确保数据通信的有序进行，避免通信过程中不会出现接收方来不及接收而造成数据丢失。**

**4. 链路控制：包括数据链路的建立、链路的维持和释放，**

**5. MAC寻址：寻找地址是计算机网卡的MAC地址，与寻址ip地址不同**

**6. 区分数据和控制信息：在许多情况下，数据和控制信息处于同一帧中**

**7. 透明传输：可以让无论是哪种比特组合的数据，都可以在数据链路上进行有效传输。**

### 信道分类

- 广播信道

  - 信道复用

    频分复用
    时分复用
    统计时分复用
    码分复用
    波分复用

  - CSMA/CD协议

    载波监听多点接入/碰撞检测
    多点接入说明是总线型网络

  > **CSMA/CD**
  > 其原理可总结为：先听后发，边发边听，冲突停发，随机延迟后重发。
  > 采用该协议要求设备在发送帧的同时要对信道进行侦听，以确定是否会发生信道冲突，若在发送数据过程中检测到冲突，则需要进行冲突处理。整个协议的处理规程如下：
  > 1 监听当前信道上是否有数据再发送，如果信道空闲，直接发送数据，如果信道忙，则按照一定的退避算法进行延时监听。
  > 2 当信道允许发送数据时，发送数据。
  >
  > 3 数据发送过程中，边发送边监听，如果发送过程中检测到冲突，则停止发送数据，并发送阻塞信息，强化冲突，并转入1。
  >
  > **CSMA/CA**采用该协议要求设备要主动避免冲突而非被动侦测的方式来解决冲突问题。避免冲突的方法主要有两个：
  > 一是监听到信道空闲时，并不是立即发送，而是等待一段时间再发送数据。
  > 二是先发送一个很小的信道侦测帧RTS，如果收到最近的接入点返回的CTS，就认为信道是空闲的，然后再发送数据。
  > 协议的主要流程如下：
  > 1 首先检测信道是否有使用，如果检测出信道空闲，则等待一段随机时间后，才送出数据。
  > 2 接收端如果正确收到此帧，则经过一段时间间隔后，向发送端发送确认帧ACK。
  > 3 发送端收到ACK帧，确定数据正确传输，在经历一段时间间隔后，再发送数据。

- 点对点信道

	- PPP协议

	  互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。

### MAC地址

唯一标识网络适配器

### 局域网

局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。
主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。


星型 环形 直线型

### 以太网

星型拓扑结构局域网

早期使用集线器，可能会发生碰撞
目前使用交换机（即插即用）代替，不会发生碰撞，能根据 MAC 地址进行存储转发。

千兆以太网以全双工和半双工方式工作

CSMA/CD工作在半双工下的冲突检测

以太网（10BASE-T、100BASE-T标准）物理拓扑结构为星型，逻辑拓扑结构为总线型。

## 网络层

### IP数据报格式

### IP编址方式

A类地址：1.0.0.0~126.255.255.254

B类地址：128.0.0.0~191.255.255.255

C类地址：192.0.0.0~223.255.255.255

D类表示的地址范围是224.0.0.0到239.255.255.255

E类表示的地址范围是240.0.0.0到255.255.255.255

> A类地址中，10.0.0.0到10.255.255.255是私有地址
>
> 在B类地址中，172.16.0.0到172.31.255.255是私有地址
>
> 在C类地址中，192.168.0.0到192.168.255.255是私有地址
>
> 127.0.0.1 本机回送地址  做测试用

IP子网划分

- B类地址有16位是主机号的位数
- 公式：![图片说明](https://www.nowcoder.com/equation?tex=%E5%AD%90%E7%BD%91%E5%86%85%E4%B8%BB%E6%9C%BA%E6%95%B0%3D2%5E%7Bx%7D-2%EF%BC%88x%E6%98%AF%E4%B8%BB%E6%9C%BA%E5%8F%B7%E7%9A%84%E4%BD%8D%E6%95%B0%EF%BC%89)
- 减去的2个一个是主机号全为0的**网络地址**，另一个主机号全1是**广播地址**
- 记住：网络地址+1是第一个主机地址，广播地址-1是最后的主机地址

### IPV6

```
IPv6地址类型可分为单播地址，组播地址和任播地址，不是广播地址。
单播地址：可作为原地址和目的地址。单点发送。
组播地址和任播地址，目的地址可有多个。任播地址：标识网络中的一组主机，只可作为IPv6分组的目的地址，但当向一个任播地址发送IP分组时，只有该任播地址标识的任播组的某个成员收到该IP分组。组播地址是组播地址标识的多播组每个成员都会收到一个该IP分组的一个副本。
```

### 虚拟专用网

### NAT

### 路由器

- 功能

  - 分组转发

    从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
    若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
    若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
    若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
    若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
    报告转发分组出错。
    > IP地址与网络地址的区别就是IP地址可分配给主机，网络地址不可分配给主机。IP地址一般是指主机的地址。网络地址是网络地址（网络号）路由器或三层交换机对数据包进行路由选择的。子网掩码和IP地址相与得到了了网络地址。
    子网掩码和IP地址相与得到了了网络地址。

  - 路由选择

    路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。
    可以把路由选择协议划分为两大类：
    自治系统内部的路由选择：RIP 和 OSPF
    自治系统间的路由选择：BGP
    
    
    1. 内部网关协议 RIP
    RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。
    RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。
    距离向量算法：
    对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1；
    对修改后的 RIP 报文中的每一个项目，进行以下步骤：
    若原来的路由表中没有目的网络 N，则把该项目添加到路由表中；
    否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。
    若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。
    RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。
    
    2. 内部网关协议 OSPF
    开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。
    开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。
    OSPF 具有以下特点：
    向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
    发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
    只有当链路状态发生变化时，路由器才会发送信息。
    所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。
    
    3. 外部网关协议 BGP
        BGP（Border Gateway Protocol，边界网关协议）
        AS 之间的路由选择很困难，主要是由于：互联网规模很大；
        各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量；
    
      BGP 系统的主要功能是和其他的BGP系统交换网络可达信息
    
      AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。
      BGP 只能寻找一条比较好的路由，而不是最佳路由。
      每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。

- 结构

  交换结构、一组输入端口和一组输出端口。
  
- 实现交换结构的方法有三种常用的方法：

  1、通过存储器

  2、通过总线

  3、通过互联网络

## 传输层

### TCP

TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工的（full-duplex）协议。

> **为什么说是面向连接？**

面向连接的协议要求正式发送数据之前需要通过「三次握手」建立一个**逻辑**连接，结束通信时也是通过有序的四次挥手来断开连接。

> **为什么说是可靠的？**

IP协议是无连接的，不可靠的，不保证对方一定能够收到包，也不保证包发送顺序与到达顺序一致，也不保证包是否重复，而tcp主要做了以下几点保证传输可靠：

- 为每个包提供校验和
- 包的序列号解决了接收数据的乱序、重复问题
- 超时重传
- 流量控制、拥塞机制

![image-20220218225551988](D:\NOTES\计网\计网.assets\image-20220218225551988.png)

![image-20220218225621492](D:\NOTES\计网\计网.assets\image-20220218225621492.png)

> 为什么说是面向字节流的？

TCP是面向字节流的传输协议，流的含义是没有固定的报文边界，消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

> 往socket里写入两段不同字节数的数据，最终以几条报文发送，每条报文的长度为多少是不知道的，接收方从套接字中读取时也不知道发送方每次写入的字节数是多少。取决于诸多因素，如路径最大传输单元MTU、发送窗口大小，接收窗口大小。

> 为什么说是全双工？

通信双方在任意时刻既可以发送数据，也可以接收数据，独立管理滑动窗口大小、序列号、MSS等信息。

![image-20220218230924974](D:\NOTES\计网\计网.assets\image-20220218230924974.png)

### 首部字段

![image-20220219104003636](D:\NOTES\计网\计网.assets\image-20220219104003636.png)

#### 序列号

序列号（Sequence number）指的是本报文段第一个字节的序列号。在 SYN 报文中，序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序。

# todo 序列号回绕

#### 确认号

TCP 使用确认号（Acknowledgment number, ACK）来告知对方下一个期望接收的序列号，小于此确认号的所有字节都已经收到。

关于确认号有几个注意点：

- 不是所有的包都需要确认的
- 不是收到了数据包就立马需要确认的，可以延迟一会再确认
- ACK 包本身不需要被确认，否则就会无穷无尽死循环了
- 确认号永远是表示小于此确认号的字节都已经收到

#### flags

8位字段，使用时相应位置1，可组合使用

- SYN（Synchronize）：用于发起连接数据包同步双方的初始序列号
- ACK（Acknowledge）：确认数据包
- RST（Reset）：这个标记用来强制断开连接，通常是之前建立的连接已经不在了、包不合法、或者实在无能为力处理
- FIN（Finish）：通知对方我发完了所有数据，准备断开连接，后面我不会再发数据包给你了。
- PSH（Push）：告知对方这些数据包收到以后应该马上交给上层应用，不能缓存起来

#### 窗口大小

16位，最大65536。

TCP 协议引入了「TCP 窗口缩放」选项 作为窗口缩放的比例因子，比例因子值的范围是 0 ~ 14，其中最小值 0 表示不缩放，最大值 14。比例因子可以将窗口扩大到原来的 2 的 n 次方，

窗口缩放值在三次握手的时候指定

#### 可选项

- MSS：最大段大小选项，是 TCP 允许的从对方接收的最大报文段
- SACK：选择确认选项
- Window Scale：窗口缩放选项

### MTU与MSS

#### MTU

数据链路层所能传输的最大的数据包的大小被称为最大传输单元

以太网的帧最小的帧是 64 字节，除去 14 字节头部和 4 字节 CRC 字段，有效荷载最小为 46 字节。最大的帧是 1518 字节，除去 14 字节头部和 4 字节 CRC，有效荷载最大为 1500，这个值就是以太网的 MTU。

不同的数据链路层的 MTU 是不同的。

![image-20220219122047537](D:\NOTES\计网\计网.assets\image-20220219122047537.png)

> ## 路径 MTU

一个包从发送端传输到接收端，中间要跨越很多个网络，每条链路的 MTU 都可能不一样，这个通信过程中最小的 MTU 称为「路径 MTU（Path MTU）

#### MSS

TCP 最大段大小（Max Segment Size，MSS）

TCP 为了避免被发送方分片，会主动把数据分割成小段再交给网络层，最大的分段大小称之为 MSS（Max Segment Size）。

```
MSS = MTU - IP header头大小 - TCP 头大小
```

这样一个 MSS 的数据恰好能装进一个 MTU 而不用分片。

#### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。

这看起来井然有序，但这存在隐患的，**那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**。

因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。

因此，可以得知由 IP 层进行分片传输，是非常没有效率的。

所以，为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。

### 三次握手

#### 状态变化

![image-20220219133926468](D:\NOTES\计网\计网.assets\image-20220219133926468.png)

#### 双方同时打开

![image-20220219134230851](D:\NOTES\计网\计网.assets\image-20220219134230851.png)

以其中一方为例，记为 A，另外一方记为 B

- 最初的状态是`CLOSED`
- A 发起主动打开，发送 `SYN` 给 B，然后进入`SYN-SENT`状态
- A 还在等待 B 回复的 `ACK` 的过程中，收到了 B 发过来的 `SYN`，what are you 弄啥咧，A 没有办法，只能硬着头皮回复`SYN+ACK`，随后进入`SYN-RCVD`
- A 依旧死等 B 的 ACK
- 好不容易等到了 B 的 ACK，对于 A 来说连接建立成功

<hr/>

- SYN 段长度为 0 却需要消耗一个序列号，原因是 SYN 段需要对端确认
- ACK 段长度为 0，不消耗序列号，也不用对端确认
- ISN 不能从一个固定的值开始，原因是处于安全性和避免前后连接互相干扰

#### 自连接

![image-20220225183225823](D:\NOTES\计网\计网.assets\image-20220225183225823.png)

对应上方tcp同时打开的情况

过程：

**当一方主动发起连接时，操作系统会自动分配一个临时端口号给连接主动发起方**。如果刚好分配的临时端口是 50000 端口，过程如下。

- 第一个包是发送 SYN 包给 50000 端口
- 对于发送方而已，它收到了这个 SYN 包，以为对方是想同时打开，会回复 SYN+ACK
- 回复 SYN+ACK 以后，它自己就会收到这个 SYN+ACK，以为是对方回的，对它而已握手成功，进入 ESTABLISHED 状态

有以下危害：

- 自连接的进程占用了端口，导致真正需要监听端口的服务进程无法监听成功
- 自连接的进程看起来 connect 成功，实际上服务是不正常的，无法正常进行数据通信

解决自连接有两个常见的办法。

- 让服务监听的端口与客户端随机分配的端口不可能相同即可

> 客户端随机分配的范围由 `/proc/sys/net/ipv4/ip_local_port_range` 文件决定，这个值的范围是 32768~60999，只要服务监听的端口小于 32768 就不会出现客户端与服务端口相同的情况。这种方式比较推荐。

- 出现自连接的时候，主动关掉连接

> 判断是否是自连接的逻辑是判断源 IP 和目标 IP 是否相等，源端口号和目标端口号是否相等。

#### 第一次握手丢失了会怎么样？

会触发超时重传机制，每次超时的时间是上一次的两倍，1+2+4+8+16+32 = 63 ,大概一分钟

#### 第二次握手丢失了会怎么样?

客户端期望收到对方的ack+syn报文，丢失之后会触发客户端的超时重传机制，而服务端也期望收到自己发送的初始序列号对应的ack报文，因此也会进行报文重传。

#### 第三次握手丢失了，会发生什么？

这会触发服务端的重传机制，知道服务端收到对应的ack报文，或者超过超时重传的次数才会停止

#### 为什么 SYN 段不携带数据却要消耗一个序列号呢？

凡是消耗序列号的 TCP 报文段，一定需要对端确认。如果这个段没有收到确认，会一直重传直到达到指定的次数为止。

#### 初始序列号 ISN 是如何随机产生的？

ISN基于时钟，每4毫秒+1

ISN = M + F(localhost, localport, remotehost, remoteport)

M 每4毫秒+1

F是根据源ip，目的ip, 源端口，目的端口通过hash算法算出来的一个值

#### ISN能够设置成一个固定值？

不能

1. 处于安全性考虑，容易被伪造RST包，进而强制关闭连接。
2. 端口允许重用，收到一个包以后不知道新连接的还是旧连接的包因为网络的原因姗姗来迟，造成数据的混淆。如果采用动态增长的 ISN，那么很大程度上保证两个连接的 ISN 不会相同，不会串包。（会有序列号回绕的问题）

#### **为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。**

- 三次握手才可以阻止重复历史连接的初始化（主要原因）

  在网络拥堵的情况下，客户端多次发送SYN报文，最新的SYN报文被阻塞，导致一个旧的SYN报文比最新的SYN报文先到达服务端，服务端接收之后，向客户端返回SYN+ACK报文，客户端对比返回报文的序列号与自己期望的下一个报文的序列号，发现不一致，于是返回RST报文，阻止了历史连接的建立。

  如果是只是两次握手就建立连接，当服务端接收到SYN报文后直接进入established状态，可以向客户端发送数据，而只有当客户端接收到服务端返回的SYN+ACK报文之后，才知道刚建立的连接是历史连接，服务端只有接收到客户端返回的RST报文后才会结束这个历史连接，这就造成了服务端资源的浪费。

- 三次握手才可以同步双方的初始序列号

  通过序列号可以去除重复报文，接收方可以根据序列号按序接收，可以标识发送出去的数据中哪些已经被对方收到（SACK)，因此保证双方序列号可靠地同步非常重要。客户端发送SYN报文给服务端，然后接收到服务端发送SYN+ACK报文，表明客户端的SYN已经被对方接收，相应地服务端发送的初始序列号也需要得到对方的确认，两次握手不能保证服务端发送的SYN报文被对方接收。

- 三次握手才可以避免资源浪费

  如果只有两次握手，当客户端发送的SYN报文在网络中阻塞，客户端未收到服务端的ACK报文，会不断重发SYN报文，由于没有第三次握手，服务端不确定客户端是否收到自己的ACK报文，因此每收到一个SYN报文，就会主动建立一个连接。这会造成服务端建立多个冗余的无效连接，造成服务端资源浪费。

  

> 

### 四次挥手

#### 挥手流程

![image-20220219152334432](D:\NOTES\计网\计网.assets\image-20220219152334432.png)



1、客户端调用 `close` 方法，执行「主动关闭」，会发送一个 FIN 报文给服务端，从这以后客户端不能再发送数据给服务端了，客户端进入`FIN-WAIT-1`状态。FIN 报文其实就是将 FIN 标志位设置为 1。

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/6/26/16b911c69b0f0f8e~tplv-t2oaga2asx-watermark.awebp)



> FIN 段是可以携带数据的，比如客户端可以在它最后要发送的数据块可以“捎带” FIN 段。当然也可以不携带数据。不管 FIN 段是否携带数据，都需要消耗一个序列号。
>
> 客户端发送 FIN 包以后不能再发送数据给服务端，但是还可以接受服务端发送的数据。这个状态就是所谓的「半关闭（half-close）」
>
> 主动发起关闭的一方称为「主动关闭方」，另外一段称为「被动关闭方」。

2、服务端收到 FIN 包以后回复确认 ACK 报文给客户端，服务端进入 `CLOSE_WAIT`，客户端收到 ACK 以后进入`FIN-WAIT-2`状态。

3、服务端也没有数据要发送了，发送 FIN 报文给客户端，然后进入`LAST-ACK` 状态，等待客户端的 ACK。同前面一样如果 FIN 段没有携带数据，也需要消耗一个序列号。

4、客户端收到服务端的 FIN 报文以后，回复 ACK 报文用来确认第三步里的 FIN 报文，进入`TIME_WAIT`状态，等待 **2 个 MSL** 以后进入 `CLOSED`状态。服务端收到 ACK 以后进入`CLOSED`状态。

#### 第一次挥手丢失

触发客户端超时重传

#### 第二次挥手丢失

客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。

#### 第二次挥手丢失

服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭,  丢失之后触发服务端重传机制，直到收到ack或者达到重传次数。

#### 2> 为什么 FIN 报文要消耗一个序列号

简单的说，同三次握手阶段的syn报文一样，FIN报文需要得到对方的确认，所以即使没有携带数据，也要消耗一个序列号，如果说FIN报文不消耗序列号，那么无法分别出得到的ACK报文是属于FIN报文的确认包，还是属于发出FIN报文前发出的数据包的确认包。

#### 3> 为什么挥手要四次，变为三次可以吗？

一般情况下，挥手需要四次，主动关闭方发送FIN报文给被动关闭方，说明主动关闭方已经不会再发送数据，被动关闭方接收到FIN后，往往不会立即返回FIN，必须等到所有数据发送完毕后才会发送FIN。因此被动关闭方会先发送一个ACK表明已经收到客户端的FIN，延迟一段时间再发FIN，如果被动关闭方将FIN与ACK合并发送，那么长时间的延迟可能会使得主动关闭方不断重发FIN报文。但假设考虑到**延迟确认**的情况，三次也是可以的， 也就是把ACK与FIN一起发送。

#### 4> 等待两个MSL的意义？如果没有TIME_AWAIT状态，直接进入CLOSED状态会怎么样？

> 与 IP 报文头的 TTL 字段有密切的关系。
>
> IP 报文头中有一个 8 位的存活时间字段（Time to live, TTL）如下图。 这个存活时间存储的不是具体的时间，而是一个 IP 报文最大可经过的路由数，每经过一个路由器，TTL 减 1，当 TTL 减到 0 时这个 IP 报文会被丢弃。

- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

如果直接进入CLOSED状态，假如主动关闭方回应的ACK报文在网络中丢失，那么对方就会重传FIN报文，而此时主动关闭方已经关闭，不会进行回应，那么这就会造成被动关闭方不断重传FIN报文。此外，如果直接进入CLOSED状态，复用该端口创建一个新连接，假设此时被动关闭方仍然处于LAST_ACK状态，未收到ACK报文，此时被动关闭方收到SYN报文后会直接返回RST报文，导致三次握手失败。

#### 5> 同时关闭会怎么样？

![image-20220219153420363](D:\NOTES\计网\计网.assets\image-20220219153420363.png)

> **这里的同时关闭中的「同时」其实并不是时间意义上的同时，而是指的是在发送 FIN 包还未收到确认之前，收到了对端的 FIN 的情况。**

以客户端为例

- 最初客户端和服务端都处于 ESTABLISHED 状态
- 客户端发送 `FIN` 包，等待对端对这个 FIN 包的 ACK，随后进入 `FIN-WAIT-1` 状态
- 处于`FIN-WAIT-1`状态的客户端还没有等到 ACK，收到了服务端发过来的 FIN 包
- 收到 FIN 包以后客户端会发送对这个 FIN 包的的确认 ACK 包，同时自己进入 `CLOSING` 状态
- 继续等自己 FIN 包的 ACK
- 处于 `CLOSING` 状态的客户端终于等到了ACK，随后进入`TIME-WAIT`
- 在`TIME-WAIT`状态持续 2*MSL，进入`CLOSED`状态

> 取决于在发送 `FIN`包之前有没有提前收到对端的 FIN 包。如果在发送 FIN 之前收到了对端的 FIN，只会有一段进入`TIME_WAIT`

### TCP 头部时间戳选项（TCP Timestamps Option，TSopt）

#### 结构

![image-20220219155826614](D:\NOTES\计网\计网.assets\image-20220219155826614.png)

#### 作用

Timestamps 选项的提出初衷是为了解决两个问题：

1、两端往返时延测量（RTTM）

> 之前是用接收到ack报文的时间减去发送对应包的时间得到的，启用timestamps后就可以利用接收到ack报文的时间减去ack报文中TSecr的值。（这里TSecr的值实际上是发送端发送报文时TSval的值，即发送时间戳）

2、序列号回绕（PAWS），接下来我们来进行介绍。

### TODO

### 半连接队列和全连接队列

- 半连接队列：服务端收到客户端的 SYN 包，回复 SYN+ACK 但是还没有收到客户端 ACK 情况下，会将连接信息放入半连接队列。半连接队列又被称为 SYN 队列。
- 全连接队列：服务端完成了三次握手，但是还未被 accept 取走的连接队列。全连接队列又被称为 Accept 队列。

![image-20220219171726608](D:\NOTES\计网\计网.assets\image-20220219171726608.png)

**全连接队列满了之后，服务器会丢掉第三次握手客户端传来的ack, 之后服务器会重发ACK + SYN，客户端收到之后也会重发ACK\**

- 1：客户端 A 发起 SYN 到服务端 B 的，开始三次握手的第一步
- 2：服务器 B 马上回复了 ACK + SYN，此时 服务器 B socket处于 SYN_RCVD 状态
- 3：客户端 A 收到服务器 B 的 ACK + SYN，发送三次握手最后一步的 ACK 给服务器 B，自己此时处于 ESTABLISHED 状态，与此同时，由于服务器 B 的全连接队列满，它会丢掉这个 ACK，连接还未建立,
- 4. 服务端 B 因为认为没有收到 ACK，以为是自己在 2 中的 SYN + ACK 在传输过程中丢掉了，所以开始重传，期待客户端能重新回复 ACK。
- 5. 客户端重传ACK, 这是全连接队列有空位，成功建立连接；否则继续重复3，4，直到重复次数到达规定值；重传的过程遵循指数级退避（1s，2s，4s，16s）

### SYN Flood攻击

#### 什么是SYN Flood攻击？

客户端大量伪造IP发送SYN包，造成服务端大量连接处于SYN_RCVD状态，充满半连接队列，使得服务器无法响应正常请求

#### 危害：

- 占满半连接队列，无法处理正常请求
- 服务器收不到客户端的ACK, 会不断重发SYN+ACK，浪费服务器资源。

#### 解决方法？

SYN Cookie：简单的说就是在三次握手的最后阶段才分配连接资源，具体地说，SYN Cookie 基于「无状态」的机制，服务端收到 SYN 包以后不马上分配为 Inbound SYN分配内存资源，而是根据这个 **SYN 包计算出一个 Cookie 值，作为握手第二步的序列号回复 SYN+ACK，**等对方回应 ACK 包时校验回复的 ACK 值是否合法，如果合法才三次握手成功，分配连接资源。

其他的方法：增加SYN连接数，即增加半连接队列的容量、减少SYN+ACK的重发次数。

### 什么是TFO？

要求客户端之前已经完成过正常的三次握手，分为两个阶段：Fast Open Cookie 和 真正开始 TCP Fast Open。



请求 Fast Open Cookie 的过程如下：（第一次三次握手）

![image-20220220093959075](D:\NOTES\计网\计网.assets\image-20220220093959075.png)

- 客户端发送 SYN 包，头部包含 Fast Open 选项，且该选项的Cookie 为空，这表明客户端请求 Fast Open Cookie
- 服务端收取 SYN 包以后，生成一个 cookie 值（一串字符串）
- 服务端发送 SYN + ACK 包，在 Options 的 Fast Open 选项中设置 cookie 的值
- 客户端缓存服务端的 IP 和收到的 cookie 值

真正的TCP Fast Open (第二次及以后的三次握手)

![image-20220220093938305](D:\NOTES\计网\计网.assets\image-20220220093938305.png)

- 客户端发送 SYN 数据包，里面包含数据和之前缓存在本地的 Fast Open Cookie。（注意我们此前介绍的所有 SYN 包都不能包含数据）
- 服务端检验收到的 TFO Cookie 和传输的数据是否合法。如果合法就会返回 SYN + ACK 包进行确认并将数据包传递给应用层，如果不合法就会丢弃数据包，走正常三次握手流程（只会确认 SYN）
- 服务端程序收到数据以后可以握手完成之前发送响应数据给客户端了
- 客户端发送 ACK 包，确认第二步的 SYN 包和数据（如果有的话）
- ![image-20220220123526015](D:\NOTES\计网\计网.assets\image-20220220123526015.png)

#### TFO优势

在开启 TCP Fast Open以后，从第二次请求开始，服务端验证SYN包携带的SYN cookie合法后，服务端就可以向客户端发送响应，因此客户端就可以在一个 RTT 时间拿到响应的数据。

### TIME_WAIT状态

#### MSL：Max Segment Lifetime

MSL（报文最大生存时间）是 TCP 报文在网络中的最大生存时间。这个值与 IP 报文头的 TTL 字段有密切的关系。IP 报文头中有一个 8 位的存活时间字段（Time to live, TTL）如下图。 这个存活时间存储的不是具体的时间，而是一个 IP 报文最大可经过的路由数，每经过一个路由器，TTL 减 1，当 TTL 减到 0 时这个 IP 报文会被丢弃。

#### TIME_WAIT存在的原因？

- 使网络中旧连接的重复报文段过期失效，避免用相同源端口和目标端口创建的新连接收到上一个连接的数据包。

  > ![image-20220220124426484](D:\NOTES\计网\计网.assets\image-20220220124426484.png)

- 确保可靠实现TCP全双工终止连接。在四次挥手的过程中，最终的ACK报文由主动关闭方发出，如果该ACK报文丢失，对端将重发FIN报文，因此如果主动关闭方没有TIME_WAIT状态直接进入CLOSED状态，则无法重传ACK，导致被动关闭方无法及时可靠释放。此外，如果发送ACK报文后，主动关闭方直接进入CLOSED状态，并重用端口建立新连接，向对端发送SYN报文，假设对端此时还未收到ACK报文，仍处于LAST_ACK状态，那么对端收到SYN报文后将返回RST报文，导致三次握手失败。

#### Time_wait状态过多

- 第一是内存资源占用；
- 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；

客户端（发起连接方）受端口资源限制：

- 客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。

服务端（被动连接方）受系统资源限制：

- 由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口。但是连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。

#### 为什么时间是两个MSL？

- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

### RST

#### 产生RST包的场景

- 端口未监听 

  > 这样机制可以用来检测对端端口是否打开，发送 SYN 包对指定端口，看会不会回复 SYN+ACK 包。如果回复了 SYN+ACK，说明监听端口存在，如果返回 RST，说明端口未对外监听，如下图所示
  >
  > ![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/6/19/16b6dd217748a3d1~tplv-t2oaga2asx-watermark.awebp)

- #### 一方突然断电重启，之前建立的连接信息丢失，另一方并不知道

#### RST包丢失了怎么办？

RST包不需要确认

在 RST 没有丢失的情况下，发出 RST 以后服务端马上释放连接，进入 CLOSED 状态，客户端收到 RST 以后，也立刻释放连接，进入 CLOSED 状态。假如服务端发送RST包进入CLOSED状态，但RST包丢失，客户端不知情，当有数据需要发送时，会直接发送，此时服务端直接返回RST，如果依然丢失，进入数据重传阶段，会在一定次数之后放弃。

![image-20220220140925301](D:\NOTES\计网\计网.assets\image-20220220140925301.png)

### TCP流量控制——滑动窗口

#### 发送窗口与接收窗口

抓包中显示的win是向对方现实自己接收窗口的大小，对方收到后根据这个值调整自己的发送窗口大小。

从 TCP 角度而言，数据包的状态可以分为已发送已确认、已发送未确认、未发送但接收端可以接收、未发送

![image-20220308120000678](D:\NOTES\计网\计网.assets\image-20220308120000678.png)

**发送窗口**是 TCP 滑动窗口的核心概念，它表示了在某个时刻一端能拥有的最大未确认的数据包大小（最大在途数据），发送窗口是发送端被允许发送的最大数据包大小

#### TCP window full 与 TCP zero window

这两者都是发送速率控制的手段，

- TCP Window Full 是站在**发送端**角度说的，表示在途字节数等于对方接收窗口的情况，此时发送端不能再发数据给对方直到发送的数据包得到 ACK。
- TCP zero window 是站在**接收端**角度来说的，是接收端接收窗口满，告知对方不能再发送数据给自己。

#### 零窗口探测

发送端的滑动窗口变为0之后，会发送零窗口探测包（一个ack包），检测对方接收窗口是否有空余

> 与之前介绍的 Syn Flood 攻击类似，上面的零窗口探测也会成为攻击的对象。试想一下，一个客户端利用服务器上现有的大文件，向服务器发起下载文件的请求，在接收少量几个字节以后把自己的 window 设置为 0，不再接收文件，服务端就会开始漫长的十几分钟时间的零窗口探测，如果有大量的客户端对服务端执行这种攻击操作，那么服务端资源很快就被消耗殆尽。

### 拥塞控制

拥塞处理主要涉及到下面这几个算法

- 慢启动（Slow Start）
- 拥塞避免（Congestion Avoidance）
- 快速重传（Fast Retransmit）和快速恢复（Fast Recovery）

#### 拥塞窗口

>  MSS是 TCP 允许的从对方接收的最大报文段

拥塞窗口指的是在收到对端 ACK 之前自己还能传输的最大 MSS 段数。

接收窗口(rwnd)是接收端的限制，表示接收端还能接收的数据大小

拥塞窗口是(cwnd)发送端的限制，表示在收到对端ACK前还能发送的数据大小

真正的发送窗口大小 = 「接收端接收窗口大小」 与 「发送端自己拥塞窗口大小」 两者的最小值

如果接收窗口比拥塞窗口小，表示接收端处理能力不够。如果拥塞窗口小于接收窗口，表示接收端处理能力 ok，但网络拥塞。

发送端和接收端不会交换 cwnd 这个值，这个值是维护在发送端本地内存中的一个值，发送端和接收端最大的在途字节数（未经确认的）数据包大小只能是 rwnd 和 cwnd 的最小值。

#### 慢启动

> 什么是慢启动？

每个 TCP 连接都有一个拥塞窗口的限制，最初这个值很小，随着时间的推移，在不丢包的情况下每次发送的数据量“慢慢”的递增，这种机制被称为「慢启动」

> 算法的过程如下：
>
> - 第一步，三次握手以后，双方通过 ACK 告诉了对方自己的接收窗口（rwnd）的大小，之后就可以互相发数据了
> - 第二步，通信双方各自初始化自己的「拥塞窗口」（Congestion Window，cwnd）大小。
> - 第三步，cwnd 初始值较小时，每收到一个 ACK，cwnd + 1，每经过一个 RTT，cwnd 变为之前的两倍。

#### 拥塞避免

当 cwnd > ssthresh(慢启动阈值) 时，拥塞窗口进入「拥塞避免」阶段，在这个阶段，每一个往返 RTT，拥塞窗口大约增加 1 个 MSS 大小，直到检测到拥塞为止。

#### 快速重传

快速重传的含义是：当接收端收到一个不按序到达的数据段时，TCP 立刻发送 1 个重复 ACK，而不用等有数据捎带确认，**当发送端收到 3 个或以上重复 ACK，就意识到之前发的包可能丢了，于是马上进行重传，**不用傻傻的等到重传定时器超时再重传。在收到重传的包之前收到的其他包会通过SACK(选择确认)的方式告知发送方这些包已经收到。

> 

![image-20220220171343211](D:\NOTES\计网\计网.assets\image-20220220171343211.png)	> **选择确认 SACK**与快速重传配合使用，





![image-20220220171507772](D:\NOTES\计网\计网.assets\image-20220220171507772.png)



#### 快速恢复

当收到三次重复 ACK 时，进入快速恢复阶段。解释为网络轻度拥塞。

- 拥塞阈值 ssthresh 降低为 cwnd 的一半：ssthresh = cwnd / 2
- 拥塞窗口 cwnd 设置为 ssthresh
- 拥塞窗口线性增加

> 慢和快不是指的拥塞窗口增长的速度，而是指它们的初始值。慢启动初始值一般都很小，快速恢复的 cwnd 设置为 ssthresh

### 延迟确认

#### 定义

如果收到一个数据包以后暂时没有数据要分给对端，它可以等一段时间（Linux 上是 40ms）再确认。如果这段时间刚好有数据要传给对端，ACK 就可以随着数据一起发出去了。如果超过时间还没有数据要发送，也发送 ACK，以免对端以为丢包了。这种方式成为「延迟确认」。

#### 场景

- 如果接收到了大于一个frame 的报文，且需要调整窗口大小
- 处于 quickack 模式（tcp_in_quickack_mode）
- 收到乱序包（We have out of order data.）

其它情况一律使用延迟确认的方式

#### 问题

Nagle 算法和延迟确认本身并没有什么问题，但一起使用就会出现很严重的性能问题了。Nagle 攒着包一次发一个，延迟确认收到包不马上回。

> **nagle算法**
>
> - 就算是 1byte 的小包也立即发送
> - 后面发送数据时需要累积数据包直到满足下面的条件之一才会继续发送数据：
>   - 数据包达到最大段大小MSS
>   - 接收端收到之前数据包的确认 ACK
>
> Nagle 算法是时代的产物，可能会导致较多的性能问题，很多组件为了高性能都默认禁用掉了这个特性。
>
> 场景：对 ssh 这种交互式的应用场景，选择开启 Nagle 算法可以使得不再那么频繁的发送小包，而是合并到一起，代价是稍微有一些延迟。现在的 ssh 客户端已经默认关闭了 Nagle 算法。

### keepalive机制

一个 TCP 连接上，如果通信双方都不向对方发送数据，那么 TCP 连接就不会有任何数据交换。通过定时发送探测包来探测连接的对端是否存活，不过默认情况下需要 7200s 没有数据包交互才会发送 keepalive 探测包，往往这个时间太久了，我们熟知的很多组件都没有开启 keepalive 特性，而是选择在应用层做心跳机制。

#### ESTABLISHED 状态的连接收到乱序包会回复什么

> Linux 内核对于收到的乱序 SYN 报文，会回复一个携带了正确序列号和确认号的 ACK 报文。

这个 ACK 被称之为 Challenge ACK。	

记发送 SYN 报文的一端为 A，处于 ESTABLISHED 状态接收 SYN 报文的一端为 B，B 对收到的 SYN 包回复 ACK 的原因是**想让对端 A 确认之前的连接是否已经失效，以便做出一些处理。**

对于 A 而已，如果之前的连接还在，对于收到的 ACK 包，正常处理即可，不再讨论。

如果 A 之前的此条连接已经不在了，此次 SYN 包是想发起新的连接，对于收到的 ACK 包，会立即回复一个 RST，且 RST 包的序列号就等于 ACK 包的序列号，B 收到这个合法的 RST 包以后，就会将连接释放。A 此时若想继续与 B 创建连接，则可以选择再次发送 SYN 包，重新建连，如下图所示。



![estab_syn](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/2/2/170047c916cc0d37~tplv-t2oaga2asx-watermark.awebp)

### TCP 和 UDP 的区别

#### 连接方面：

- TCP 是面向连接的传输层协议传输之前首先要建立连接。
- UDP 是不需要建立连接的，即可传输数据。

服务对象：

1. TCP是一对一的两点服务，即一条连接只有两个端点。
2. UDP支持一对一、一对多、多对多的交通通信。

可靠性：

- TCP是可靠交付数据的，数据可以无差别、不丢失、不重复、按需到达。
- UDP是尽最大可能交付，不保证可靠交付数据。

拥塞控制、流量控制：

- TCP有拥塞控制和流量控制机制，考证数据传输的安全性。
- UDP则没有，即使网络非常拥堵了，也不会影响UDP的发送速率。

首部开销：

- TCP手部长度较长，会有一定的开销，首部在没有使用【选项】字段有20个字节，如果使用了【选项】字段会更长。
- UDP首部只有8个字节，并且是固定不变的、开销较小。

传输方式：

- TCP是流式传输、没有边界，但保证顺序和可靠。

#### 应用场景

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

## 应用层

### 域名系统

DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。
可以使用TCP或者udp传输，端口号为53；
大部分情况下使用udp传输，下面两种情况使用tcp
如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。
区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）

> DNS 服务的常见资源记录类型：A记录（主机地址）、CNAME记录（别名）、MX记录（邮件主机）、NS记录（名称服务器）、SOA记录（起始授权机构）、PTR记录（IP反向解析）、SRV记录（MS DNS服务器的活动目录）

### 文件传送协议

FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：
控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后
数据连接：用来传送一个文件数据。
根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：
主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。
被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。、

主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。

### 动态主机配置协议

discover -> offer -> request -> ack
使用udp传输
DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。
DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。
DHCP 工作过程如下：
客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。
DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。
如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。
DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

### 电子邮件协议

发送： SMTP
读取： POP3 ， IMAP

- SMTP
- POP3
- IMAP

### Web 页面请求过程

1. DHCP 配置主机信息
假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。

主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF，将广播到与交换机连接的所有设备。
连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

2. ARP 解析 MAC 地址
主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。

主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:<zero-width space>FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

3. DNS 解析域名
知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。

网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

4. HTTP 请求页面
有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。

在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

### HTTP

#### HTTP 篇

#### get 与 post的关系

get的含义就是获取网络资源。

post的含义就是发布新的网络资源。

安全、幂等方面，在安全方面，他们都是明文传输存在安全的问题。然后就是get只是获取服务器的资源，不会对服务器内容进行修改所以说，不存在安全问题。

从缓存的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会

对于幂等方面，get请求得到的结果都是一样的，但是对于post而言却不是一样的。

.GET请求会产生一次TCP数据包,浏览器会把http,header,data一并发送出去

　　　POST请求会产生两次TCP数据包  浏览器先发送请求头,服务器响应100 continue,  浏览器再发送请求体

#### HTTP 的特征

优点：

- 良好的跨平台性

不足：

- 明文传输
- 无状态
- 队头阻塞问题

#### HTTP/1.1 的特点

1.长链接 connection：keep-alive

> TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。 持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。

2.管道网络传输，pipline

> 允许客户端同时发起多个连接，不用等待其响应返回之后再发起新的连接，减少整体响应时间。

3.队头阻塞。

请求按照顺序排成队列灯带服务端处理，如果前面某一个请求的处理时间过长就会造成堵塞，影响后续请求的处理，这就是队头阻塞。

#### HTTP 与 HTTPS 的区别？

1.HTTP是超文本传输协议，信息是明文传输，存在安全风险。对于https而言就不存在这样的问题，https在tcp和http中使用了ssl/tls来进行数据加密。

2.HTTP的建立过程相对来说简单一些，HTTP在进行了tcp/ip协议的三次握手之后建立了链接就可以进行报文传输了。然而HTTPS在TCP三次握手之后还需要进行TLS/SSL的握手才能进行通信。

3.HTTP的端口号是80，HTTPS的端口号为443.

4.HTTPS需要向CA机构申请数字证书，来保证服务器身份的可信度。

#### http相比https的问题

1. 窃听风险，明文传输，通过抓包工具就可以获取到http传输过程中的数据内容。
2. 篡改风险，通过抓包工具可以获取到http传输的内容进行修改之后，再发送出去。
3. 冒充风险，由于冒充者可以收到发送方的信息，那么冒充者就可以冒充真正的发送方给接收方发送信息。

#### https如何解决这些问题？

HTTPS在HTTP和TCP层之间加入了SSL/TLS协议，可以很好的解决这个问题

1. 信息加密，解决的窃听风险。
2. 校验机制，因为https传输中都有校验和，如果被修改了，校验和将无法通过。
3. 身份证书，对于冒充风险而言，利用权威机构发布的CA就可以证明该服务器的身份。

**HTTPS如何来解决HTTP的三个问题的呢？**

1. 混合加密，首先是HTTPS使用混合加密的方式来解决窃听风险。
2. 摘要算法，摘要算法的方式去实现完整性。他可以使得数据生成独一无二的指纹，指纹用于校验传输数据的完整性，解决了篡改的风险。
3. CA中存放服务器公钥，冒充风险，主要来源于密钥传输的可能存在风险，那么我们就可以直接将公钥放置在证书中，让别人无法去篡改公钥，而后实现加密通信。

下面是以上三个问题的详细展开：

1. **混合加密：**HTTPS使用的是对称加密和非对称加密相结合的混合加密方式。解决了通信过程中的窃听风险，保证了信息的机密性

2. > - 在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。 
   >
   > - 在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。
   >
   >    采⽤「混合加密」的⽅式的原因：
   >
   >   - 对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。 
   >   - ⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题,但速度慢

3. 摘要算法：客户端在发送数据之前，就会将自己的数据全部进行一次hash，得出指纹，然后用于校验和，解决了篡改问题。如果在传输过程中数据被修改了那么我们的数据包就不能通过数据校验的过程。

4. 数字证书：客户端先向服务端索取公钥，然后使用公钥进行加密传输，服务端收到信息之后使用自己的私钥进行解密。但是这个时候就会存在问题，如果确保这个公钥是服务端发送过来的，中间的篡改者一样可以发送公钥给客户端，然后和客户端建立联系，然后客户端的信息产生巨大的威胁。所以就需要一个值得信任的第三方机构CA（数字证书认证机构），将服务器的公钥放到数字证书中。只要证书是可信的，那么公钥就是可信的。因此通过数字证书的方式，保证了服务器公钥的身份，解决了冒充者的问题。

#### HTTP/1.1、HTTP/2、HTTP/3 演变

> #### 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能

HTTP/1.1 相⽐ HTTP/1.0 性能上的改进： 

- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。 
- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以 减少整体的响应时间。 

但 HTTP/1.1 还是有性能瓶颈：

-  请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分； 
- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多； 
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞； 
- 没有请求优先级控制； 
- 请求只能从客户端开始，服务器只能被动响应。

> #### 那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化

1. **头部压缩**      

   > HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重 复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索 引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。 

2. **⼆进制格式** 

   > HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了**⼆进制格式**，头信息和数据体都是⼆进制，并 且统称为帧（frame）：头信息帧和数据帧。 这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转 成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输的效率。 

3. **数据流**    

   >  **HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应**。因此，必须要对数据 包做标记，指出它属于哪个回应。 每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规 定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数 客户端还可以指定数据流的优先级。**优先级⾼的请求，服务器就先响应该请求。** 

4. **多路复⽤**   

   >  HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。 移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提⾼ 了连接的利⽤率。 举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就 回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。 

   > 多路复用是建立在加载的资源在同一域名下，不同域名神仙也复用不了。

   

5. **服务器推送**     

   > HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发 送消息。 举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减 少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

> #### HTTP3相对于HTTP2的提升？

HTTP/2 主要的问题在于，**多个HTTP请求在复用一个TCP连接，下层的TCP协议是不知道有多少个HTTP请求的。所以一旦发送丢包的情况，就会触发TCP的重传机制，这样在一个TCP连接中的所有的HTTP请求都必须要去等待这个丢了的包被重传回来。**

1. HTTP/1.1中的管道（pipline）传输中如果有一个请求阻塞了，那么队列后请求也统统会被阻塞住。
2. HTTP/2多个请求复用一个TCP链接，一旦发生了丢包，就会阻塞住所有的HTTP请求。

这些其实都是在TCP传输层出了问题，所以HTTP3的时候就把HTTP下层的TCP更换为了UDP！UDP实现了一个不可靠传输，但是基于 UDP 的 QUIC 协议可以实现类似于 TCP 的可靠传输。

1. QUIC 有自己的一套机制可以保证传输的可靠性。当某一个流发生丢包的时候，只会阻塞这个流，不会影响到其他的流。
2. TLS3 升级到最新的1.3版本，头部压缩变为QPack。
3. HTTPS要建立连接的话，要花费6次交互，先是要建立三次握手，然后是TLS的三次握手。QUIC直接把之前的TCP和TLS/1.3的三次握手合并为了3次，减少了交互的次数。所以说QUIC是一个新的协议，它是一个伪TCP+TLS+HTTP/2的多路复用的协议。



### HTTPS

（record）记录是 TLS 收发数据的基本单 位，类似于 TCP ⾥的 segment。多个记录可以组合成⼀个 TCP 包发送，所以通常经过「四个消息」就可以完成 TLS 握⼿，也就是需要 2个 RTT 的时延，然后就可以在安全的通信环境⾥发送 HTTP 报⽂，实现 HTTPS 协 议

#### HTTPS  RSA握手过程？

HTTPS要建立连接的话，要花费6次交互，先是要建立三次握手，然后是TLS的三次握手。（TLS 1.3 三次 TLS1.2 四次）

SSL/TLS协议的基本流程为：客户端向服务端索取公钥，然后双方协商会话密钥，然后利用该会话密钥，进行加密通信。一共三步，前两步是SSL/TLS的建立过程，也就是握手阶段。握手阶段进行了四次通信。具体流程如下所示。

1.ClientHello

首先客户端向服务端发起加密通信请求。这一步中主要包含了以下信息。

（1）客户端支持的SSL/TLS协议版本版本。

（2）客户端生产的随机数（Client Random），后面用于生产「会话秘钥」。

（3）客户端支持的加密算法套件，如RSA加密算法。

2.ServerHello

服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容： 

（1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。 

（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。 

（3）确认的密码套件列表，如 RSA 加密算法。 

（4）服务器的数字证书

3.客户端响应

客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。 如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息： 

（1）(Client Key Exchange)⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。 

（2）（Change Cipher Spec）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。 

（3）(Encrypted Handshake Message / Finished) 客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘 要，⽤来供服务端校验

4.服务端响应

（1）(Change Cipher Spec) 加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（2）(Encrypted Handshake Message / Finished) 服务端握手结束通知，并将之前的通信做一次摘要。

至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

#### 数字证书的签发和验证流程？

CA 签发证书的过程，如上图左边部分： 

- ⾸先 CA 会把持有者的公钥、⽤途、颁发者、有效时间等信息打成⼀个包，然后对这些信息进⾏ Hash 计算， 得到⼀个 Hash 值；

- 然后 CA 会使⽤⾃⼰的私钥将该 Hash 值加密，⽣成 Certificate Signature，也就是 CA 对证书做了签名； 

- 最后将 Certificate Signature 添加在⽂件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分： 

- ⾸先客户端会使⽤同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使⽤ CA 的公钥解密 Certificate Signature 内容，得到⼀个 Hash 值 H2 ；
- 最后⽐较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信

#### 证书信任链的问题？

- 假如客户端得到一个由中间证书B签发的证书C，客户端发现C不是由根证书签发的，然后客户端从证书c的签发者中找到该证书的签发机构，向其请求中间证书B
- 请求到该证书后发现该证书是由根证书A签发的，客户端会检查该根证书是否预载于根证书清单上，如果有的话就利用该根证书中的公钥验证中间证书B, 验证通过，说明中间证书B可信
- 然后利用中间证书B中的公钥去验证证书C，如果验证通过，说明证书C可信。

#### RSA算法缺陷

**使⽤ RSA 密钥协商算法的最⼤问题是不⽀持前向保密。**因为客户端传递随机数（⽤于⽣成对称加密密钥的条件之 ⼀）给服务端时使⽤的是公钥加密的，服务端收到到后，会⽤私钥解密得到随机数。所以**⼀旦服务端的私钥泄漏 了，过去被第三⽅截获的所有 TLS 通讯密⽂都会被破解。**

为了解决前向保密的问题，就有了DH密钥协商算法

>  客户端和服务端各⾃会⽣成随机数，并以此作为私钥，然后根据公开的 DH 计算公示算出各⾃的公钥，通过 TLS 握⼿双⽅交换各⾃的公钥，这样双⽅都有⾃⼰的私钥和对⽅的公钥，然后双⽅根据各⾃持有的材料算出⼀个随机 数，这个随机数的值双⽅都是⼀样的，这就可以作为后续对称加密时使⽤的密钥。 DH 密钥交换过程中，即使第三⽅截获了 TLS 握⼿阶段传递的公钥，在不知道的私钥的情况下，也是⽆法计算出 密钥的，⽽且每⼀次对称加密密钥都是实时⽣成的，实现前向保密

因为 DH 算法的计算效率问题，后⾯出现了 ECDHE 密钥协商算法

#### HTTPS ECDHE握手

![image-20220226201654743](D:\NOTES\计网\计网.assets\image-20220226201654743.png)

**第一次握手**

> 发送Client Hello
>
> 客户端使⽤的 TLS 版本号、⽀持的密码套件列表，以及⽣ 成的随机数（Client Random）

**第二次握手**

> 发送「Server Hello」
>
> >  有服务器确认的 TLS 版本 号，⼀个随机数（Server Random），选择的密码套件。
>
> > 例：「 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384」 、
> >
> > 密钥协商算法使⽤ ECDHE； 签名算法使⽤ RSA； 握⼿后的通信使⽤ AES 对称算法，密钥⻓度 256 位，分组模式是 GCM； 摘要算法使⽤ SHA384
>
> 发送「Certificate」消息，把证书也发给客户端。
>
> 发送「Server Key Exchange」
>
> > 这个过程中做了以下事：
> >
> > - 选择了名为 named_curve 的椭圆曲线，选好了椭圆曲线相当于椭圆曲线基点 G 也定好了，这些都会公开给 客户端；
> >
> > - ⽣成随机数作为服务端椭圆曲线的私钥，保留到本地； 
> >
> > - 根据基点 G 和私钥计算出服务端的椭圆曲线公钥，这个会公开给客户端
>
> 发送「Server Hello Done」

**第三次握手**

- 验证证书，确认服务端身份

- 生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前⾯给的信息，⽣成客户端的椭圆曲线公 钥，然后⽤**「Client Key Exchange」**消息发给服务端。

⾄此，双⽅都有对⽅的椭圆曲线公钥、⾃⼰的椭圆曲线私钥、椭圆曲线基点 G，根据 ECDHE 算法计算出共享密钥x

⽤「客户端随机数 + 服务端随机数 + x（ECDHE 算法算出的共享密钥） 」三个材料⽣成会话密钥

- 算好会话密钥后，客户端会发⼀个**「Change Cipher Spec」**消息，告诉服务端后续改⽤对称算法加密通信。

- 接着，客户端会发**「Encrypted Handshake Message」**消息，把之前发送的数据做⼀个摘要，再⽤对称密钥加密 ⼀下，让服务端做个验证

**第四次握手**

发「Change Cipher Spec」和「Encrypted Handshake Message」消 息，如果双⽅都验证加密和解密没问题，那么握⼿正式完成。

#### RSA握手与ECDHE握手的区别

- RSA 密钥协商算法「不⽀持」前向保密，ECDHE 密钥协商算法「⽀持」前向保密； 
- 使⽤了 RSA 密钥协商算法，TLS 完成四次握⼿后，才能进⾏应⽤数据传输，⽽对于 ECDHE 算法，客户端可 以不⽤等服务端的最后⼀次 TLS 握⼿，就可以提前发出加密的 HTTP 数据，节省了⼀个消息的往返时间； 
- 使⽤ ECDHE， 在 TLS 第 2 次握⼿中，会出现服务器端发出的「Server Key Exchange」消息，⽽ RSA 握⼿ 过程没有该消息

#### websocket 的特点是什么？

websocket解决了一个HTTP的致命问题：请求只能由客户端发起的问题，即使HTTP2中新增了服务端推送，但是依然是在客户端发起请求之后才新增的。

HTTP协议依然不能向客户端发起推送信息。这种单向推送造成了不少的问题，就是如果说，服务器有连续的状态变化，客户端获知就非常麻烦，只能通过轮询的方法来获取。

其特点为：

- 建立在TCP之上，服务器的实现比较简单
- 与HTTP协议有着良好的兼容性。默认端口为80和443，并且握手阶段采用和HTTP一样的方式。
- 数据格式比较轻巧
- 可以发送文本，也可以放松发送二进制数据
- 没有同源策略限制
- 标识符号为ws和wss

#### HTTP/1.1 优化篇

主要有三个思路来优化HTTP1.1协议，比如有三种思路来实现。

- 尽量避免发送HTTP请求
- 在需要发送HTTP请求的时候，考虑如何减少请求次数
- 减少服务器的HTTP响应数据大小

下面就针对这三种思路具体看看有哪些优化的方法。

##### 一、尽量避免发送请求

缓存技术，客户端会把第一次请求以及其响应的数据保存在本地磁盘中，其中可以将通过key:value的形式去保存缓存的数据。

**1.1 强制缓存，协商缓存的关系与区别：**

浏览器第一次打开一个网页获取资源后，根据返回的header信息来告诉如何缓存资源。浏览器第一次请求。



![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZdXJPgYd952K4sF5y5HSJ5EoHAibk6icXQdjic0SDeibfbPQ25NB3qSS80TtZcaAZVkDD2ZiaKX3rX3sfg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

浏览器发送请求，无缓存的情况下，请求响应之后，根据响应的头部告诉我们如何进行缓存。1.expires 有效期至什么时候。2 cache-control  3.Etag   4.last-modified

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZdXJPgYd952K4sF5y5HSJ5EAYOWpav7uasJQz68hnl9uOdfCadcia3CcyXR1XialViar2TKg1dS0ojWA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在后续的请求中，在发送之前，会首先检查本地缓存，是否含有该请求的结果。如果有的话，就先去检查其头部是否命中强制缓存（Expires 、cache-control），若命中直接从缓存中获取资源信息，包括缓存header信息，本次请求就不会与服务器进行通信。如果没有命中的话，就会发送网络请求，但是在发送的时候需要带上其头部有关的字段（Etag/If-none-match  和  Last-modified/If-modified-since）由服务器来判断是否命中协商缓存，如果命中的话，就返回一个 304 not modified，那么客户端直接从缓存中获取数据，如果返回了新的数据，那么就在缓存中更新相关的信息。

**强制缓存相关字段**

Expires策略：

expires是web服务器中响应消息头字段，在响应http请求时告诉浏览器在过期时间前浏览器可以直接从浏览器缓存取数据，而无需再次请求。Expires设置失效时间，精确到时分秒。不过Expires 是HTTP 1.0的东西，现在默认浏览器均默认使用HTTP 1.1，所以它的作用基本忽略。

Cache-control策略：

cache-control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存拿到数据还是从服务器端去获取数据。只不过Cache-control的选项更多一些，设置更加精细，如果同时设置的话，其优先级高于Expires。

Http协议头：Cache-control 其value可以为 `private`、 `no-cache` 、`no-store`、 `no-transform`、 `must-revalidate` 、`proxy-revalidate` 、`max-age`

各个消息中的指令含义如下：

1. Public指示响应可被任何缓存区缓存。
2. private指示对于单个用户的整个或者部分响应消息，不能被共享缓存处理。这允许服务器仅仅描述用户的部分响应消息，此相应消息对于其他用户的请求无效。
3. no-cache代表不缓存过期的资源，缓存会向服务器进行有效处理确认之后处理资源，do-not-serve-from-cache-without-revalidation
4. no-store表示全面禁止缓存。
5. max-age指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应。

**如果cache-control与expires同时存在的话，cache-control的优先级高于expires**

>  协商缓存的相关字段

Last-modified/If-Modified-since 和 Etag/If-None-Match 这两组搭档是成对出现的，也就说第一次请求中出现了Last-modified，那么接下来的请求中就会带上If-Modified-Since字段，如果第一次请求中带有Etag字段的话，那么接下来的请求中就会带有If-None-Match字段。

这两个字段都需要配合Cache-control来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。

Last-modified/If-Modified-since

- last-modified：标示这个响应资源的最后修改时间。web服务器在响应请求的时候，告诉服务器的请求最终修改时间。
- If-modified-since：当资源过期了，发现响应头中具有last-modified声明，则再次发起请求的时候带上last-modified的时间，服务器收到请求后发现有if-modified-since则与被请求资源的最后修改时间进行对比（Last-Modified）,若最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK;若最后修改时间较旧（小），说明资源无新修改，响应HTTP 304 走缓存。

Etag/If-None-Match

- Etag：服务器响应时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定）。Apache中，ETag的值，默认是对文件的索引节（INode），大小（Size）和最后修改时间（MTime）进行Hash后得到的。
- If-None-Match：当资源过期时，浏览器发现响应头里有Etag,则再次像服务器请求时带上请求头`if-none-match`(值是Etag的值)。服务器收到请求进行比对，决定返回200或304。

> Etag和Last-modified两者为何并存？

看上去两者的功能很是相似都是为了实现协商缓存，Etag的出现主要目的是为了解决几个Last-modified不好解决的问题。

因为有的文件是周期性变化的，对于客户端来说意义不大，不需要客户端去检测到它的变化，所以采用大的版本控制的方式去检测就可以了。这时，利用Etag能够更加准确的控制缓存，因为Etag是服务器自动生成或者由开发者生成的对应资源在服务器端的唯一标识符。

**Etag和last-modified同时存在的时候Etag的优先级更高**

#### 二、尽量减少HTTP请求次数

- 尽量减少重定向次数
- 合并请求
- 延迟发送请求

> 尽量减少重定向次数

减少重定向次数，服务器上的一个资源可能由于迁移、维护等原因从url转移到url2后，而客户端并不知道，客户端此时并不会不会简单粗暴的返回错误，而是通过302响应码和Location头部，告诉客户端该资源已经迁移到url2上了，于是客户端需要再次发送url2请求以获取到服务器资源。那么如果重定向的次数过多了，每次客户端都要多次发起HTTP请求，每一次的HTTP请求得经过网络，这无疑会降低网络性能。

301: Moved Permanently  资源永久重定向到另外一个URI

302: Found/Moved Temporarily 资源临时重定向到另外一个URI中

> 合并请求

可以将多个小文件的请求合并为一个大的请求，虽然传输的总资源是一定的，但是减少了请求的次数，这就意味着减少了重复发送HTTP头部。

> 延迟发送请求/ 按需加载

按需访问资源，只访问当前⽤户看得到/⽤得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延 迟请求，也就减少了同⼀时间的 HTTP 请求次数

#### 三、减小HTTP响应的数据大小

减少HTTP响应数据的大小，从而提高网络传输的效率。对数据进行压缩。

#### TLS1.2 与 TLS1.3的区别

> TLS1.2完成握手需要四次，两个RTT, TLS1.3完成握手只需要两次，一个RTT

 TLS 1.3 把 Hello 和公钥交换这两个消息合并成了⼀个消息， 于是这样就减少到只需 1 RTT 就能完成 TLS 握⼿。

具体的做法是，客户端在 Client Hello 消息⾥带上了⽀持的椭圆曲线，以及这些椭圆曲线对应的公 钥。 服务端收到后，选定⼀个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双⽅⼿上 已经有⽣成会话密钥的材料了，于是客户端计算出会话密钥，就可以进⾏应⽤数据的加密传输了

> TLS1.3废除了不支持前向安全的算法( RSA 和 DH 算法)，只支持ECDHE算法

> 对于对称加密和签名算法，TLS1.3只⽀持⽬前最安全的⼏个密码套件

### HTTPS优化

![image-20220226201410708](D:\NOTES\计网\计网.assets\image-20220226201410708.png)



> 会话复用

## 网络安全篇

### XSS

xss（cross-site script）

- 反射型XSS：**<非持久化>** 攻击者事先制作好攻击链接, 需要欺骗用户自己去点击链接才能触发XSS代码（服务器中没有这样的页面和内容），一般容易出现在搜索页面。比如说将script脚本放置在请求参数中，然后页面中需要用到请求参数，就会直接执行该script标签。
- 存储型XSS：**<持久化>** 代码是存储在服务器中的，如在个人信息或发表文章等地方，加入代码，如果没有过滤或过滤不严，那么这些代码将储存到服务器中，每当有用户访问该页面的时候都会触发代码执行，这种XSS非常危险，容易造成蠕虫，大量盗窃cookie（虽然还有种DOM型XSS，但是也还是包括在存储型XSS内）。同上面的情况类似，入侵者将script标签写到了数据库中，然后每次发送请求之后，每次打开页面之后都会执行script标签。

防御：

- 标签转译：分为黑名单转译，将所有的<,>,/,都给转译为其他字符。">"为"&gt" "<"为"&lt".白名单的话就是使用xss库。可以把输入的文字都给部分转译一下。

- 应为xss主要的目的是为了获取你的cookie，然后那么我只需要设置在cookie中设置，http-only，就可以了，因为xss是要先从document中获取到cookie，然后再发送出去，实际上呢我们将其设置为只有在发送http请求的时候才能带上cookie。

- CSP 内容安全策略（CSP）是一个额外的安全层，用于检测并削弱某些特定类型的攻击，包括跨站脚本和数据注入攻击等。无论是数据盗取、网站内容污染还是散发恶意软件，这些都是主要的手段。我们可以通过CSP来尽量减少XSS攻击，CSP本质上也是建立白名单，规定了浏览器只能够执行特定来源的代码。通常我们可以通过HTTP Header中的`Content-Security-Policy`来开启CSP

- - 只允许加载本站资源

    ```
    Content-Security-Policy: default-src 'self'
    ```

  - 只允许加载HTTPS协议图片

    ```
    Content-Security-Policy: img-src https://*
    ```

  - 允许加载任何来源

    ```
    Content-Security-Policy:child-src 'none'
    ```

### CSRF

CSRF（Cross-site request forgery），中文名称：跨站请求伪造，也被称为：one click attack/session riding，缩写为：CSRF/XSRF。

它主要就是利用你的浏览器保存了你的登陆信息，通过另外一个网址，在该网址中发送一个跨站请求，携带者你的身份认证，这样就可以成功的对你的账号进行操作了。

防御方式：

1. reference check，但是很多时候，reference是可以修改的。
2. cookie hash的方法，在表单中植入md5密码，虽然md5的安全性不太行，但是还是应对此问题已经够用了，因为每个表单中的随机数都是不一样的。
3. 手机验证码
4. sameSite：可以对Cookie进行设置，Samesite属性。该属性设置Cookie不随着跨域请求发送，该属性可以很大程度上减少CSRF的攻击。

### 点击劫持

这是一种视觉欺骗的方式，让你以为在点击一个正确的按钮的时候发送了一个别的请求。将该网站放置在一个iframe中，然后造成视觉的误差。

防御：

X-Frame-Options：deny

### 请求劫持

DNS劫持（DNS解析被劫持）

HTTP劫持（使用HTTPS）

### DDOS（distributed denial of service）

syn flood http flood

## 传输层



### 概述

传输层的作用是为两台主机之间的「应用进程」提供端到端的逻辑通信

为上层提供简单灵活，无连接的数据报服务
IP协议将异构的物理网络连接起来

与 IP 协议配套使用的还有三个协议：
地址解析协议 ARP（Address Resolution Protocol）
网际控制报文协议 ICMP（Internet Control Message Protocol）
为了更好地转发IP数据包和提交交付成功的机会
ICMP 报文分为差错报告报文和询问报文。
### 应用： 
Ping   
Traceroute:用来跟踪一个分组从源点到终点的路径。Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。

网际组管理协议 IGMP（Internet Group Management Protocol）

